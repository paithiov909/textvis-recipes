# æ–‡æ›¸ãƒ¡ãƒ‹ãƒ¥ãƒ¼

```{r}
#| label: setup
suppressPackageStartupMessages({
  library(ggplot2)
  library(duckdb)
})
drv <- duckdb::duckdb()
con <- duckdb::dbConnect(drv, dbdir = "tutorial_jp/kokoro.duckdb", read_only = TRUE)

tbl <-
  readxl::read_xls("tutorial_jp/kokoro.xls",
    col_names = c("text", "section", "chapter", "label"),
    skip = 1
  ) |>
  dplyr::mutate(
    doc_id = factor(dplyr::row_number()),
    dplyr::across(where(is.character), ~ audubon::strj_normalize(.))
  ) |>
  dplyr::filter(!gibasa::is_blank(text)) |>
  dplyr::relocate(doc_id, text, section, label, chapter)
```

---

## æ–‡æ›¸æ¤œç´¢ï¼ˆA.6.1ï¼‰

### TF-IDF

KWICã®çµæœã‚’æ¤œç´¢èªã®TF-IDFã®é™é †ã§ä¸¦ã³æ›¿ãˆã‚‹ä¾‹ã€‚

```{r}
#| label: kwic-arranged-tf-idf
dat <-
  dplyr::tbl(con, "tokens") |>
  dplyr::filter(section == "[1]ä¸Š_å…ˆç”Ÿã¨ç§") |>
  dplyr::select(label, token) |>
  dplyr::collect()

dat |>
  dplyr::reframe(token = list(token), .by = label) |>
  tibble::deframe() |>
  quanteda::as.tokens() |>
  quanteda::tokens_select("[[:punct:]]", selection = "remove", valuetype = "regex", padding = FALSE) |>
  quanteda::kwic(pattern = "^å‘[ã„ãã‘ã“]$", window = 5, valuetype = "regex") |>
  dplyr::as_tibble() |>
  dplyr::select(docname, pre, keyword, post) |>
  dplyr::left_join(
    dat |>
      dplyr::count(label, token) |>
      tidytext::bind_tf_idf(token, label, n),
    by = dplyr::join_by(docname == label, keyword == token)
  ) |>
  dplyr::arrange(desc(tf_idf))
```

### LexRankğŸ³

[LexRank](https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume22/erkan04a-html/erkan04a.html)ã¯ã€TF-IDFã§é‡ã¿ã¥ã‘ã—ãŸæ–‡æ›¸é–“ã®é¡ä¼¼åº¦è¡Œåˆ—ã«ã¤ã„ã¦ãƒšãƒ¼ã‚¸ãƒ©ãƒ³ã‚¯ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã€æ–‡æ›¸é›†åˆã®ãªã‹ã‹ã‚‰ã€Œé‡è¦ãªæ–‡æ›¸ã€ã‚’æŠ½å‡ºã™ã‚‹æ‰‹æ³•ã€‚

```{r}
#| label: create-dfm-1
dat <-
  dplyr::tbl(con, "tokens") |>
  dplyr::filter(
    pos %in% c(
      "åè©", # "åè©B", "åè©C",
      "åœ°å", "äººå", "çµ„ç¹”å", "å›ºæœ‰åè©",
      "å‹•è©", "æœªçŸ¥èª", "ã‚¿ã‚°"
    )
  ) |>
  dplyr::mutate(
    token = dplyr::if_else(is.na(original), token, original),
    token = paste(token, pos, sep = "/")
  )

dfm <- dat |>
  dplyr::count(label, token) |>
  dplyr::collect() |>
  tidytext::bind_tf_idf(token, label, n) |>
  dplyr::inner_join(
    dat |>
      dplyr::select(doc_id, label, token) |>
      dplyr::collect(),
    by = dplyr::join_by(label == label, token == token)
  ) |>
  tidytext::cast_dfm(doc_id, token, tf_idf)
```

æ–‡æ›¸é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’å¾—ã¦ã€PageRankã‚’è¨ˆç®—ã™ã‚‹ã€‚`quanteda.textstats::textstat_simil()`ã¯`proxyC::simil()`ã¨å‡¦ç†ã¨ã—ã¦ã¯åŒã˜ã ãŒã€æˆ»ã‚Šå€¤ãŒ`textstat_simil_symm_sparse`ã¨ã„ã†S4ã‚¯ãƒ©ã‚¹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãªã£ã¦ã„ã¦ã€`as.data.frame()`ã§ç¸¦é•·ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã§ãã‚‹ã€‚

```{r}
#| label: calc-lexrank
scores <- dfm |>
  quanteda.textstats::textstat_simil(
    margin = "documents",
    method = "cosine",
    min_simil = .6 # LexRankã®æ–‡è„ˆã§ã„ã†ã¨ã“ã‚ã®threshold
  ) |>
  as.data.frame() |>
  dplyr::mutate(weight = 1) |> # é–¾å€¤ä»¥ä¸Šã®ã‚¨ãƒƒã‚¸ã—ã‹ãªã„ã®ã§ã€é‡ã¿ã¯ã™ã¹ã¦1ã«ã™ã‚‹
  # dplyr::rename(weight = cosine) |> # ã‚ã‚‹ã„ã¯ã€é–¾å€¤ã‚’æŒ‡å®šã›ãšã«ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ãã®ã¾ã¾é‡ã¿ã¨ã—ã¦ä½¿ã†ï¼ˆcontinuous LexRankï¼‰
  igraph::graph_from_data_frame(directed = FALSE) |>
  igraph::page_rank(directed = FALSE, damping = .85) |>
  purrr::pluck("vector")
```

LexRankã¯æŠ½å‡ºå‹ã®è¦ç´„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã„ã†ã“ã¨ã«ãªã£ã¦ã„ã‚‹ãŒã€å¿…ãšã—ã‚‚è¦ç´„çš„ãªæ–‡æ›¸ãŒå¾—ã‚‰ã‚Œã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚æ–‡æ›¸é›†åˆã®ãªã‹ã§ã‚‚é¡ä¼¼åº¦ãŒæ¯”è¼ƒçš„é«˜ãã†ãªæ–‡æ›¸ã‚’nä»¶å–ã‚Šå‡ºã—ã¦ãã¦ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã¤ãã‚‹ã¿ãŸã„ãªä½¿ã„æ–¹ã¯ã§ãã‚‹ã‹ã‚‚ï¼Ÿ

```{r}
#| label: glimpse-lexrank
sort(scores, decreasing = TRUE) |>
  tibble::enframe() |>
  dplyr::left_join(
    dplyr::select(tbl, doc_id, text, chapter),
    by = dplyr::join_by(name == doc_id)
  ) |>
  dplyr::slice_head(n = 5)
```

## ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æï¼ˆA.6.2ï¼‰

### LSIğŸ³

æ–‡æ›¸å˜èªè¡Œåˆ—ï¼ˆã¾ãŸã¯ã€å˜èªæ–‡æ›¸è¡Œåˆ—ï¼‰ã«å¯¾ã—ã¦ç‰¹ç•°å€¤åˆ†è§£ã‚’ãŠã“ãªã£ã¦ã€è¡Œåˆ—ã®æ¬¡å…ƒã‚’å‰Šæ¸›ã™ã‚‹æ‰‹æ³•ã‚’LSIã¨ã„ã†ã€‚æ½œåœ¨çš„æ„å‘³ã‚¤ãƒ³ãƒ‡ã‚­ã‚·ãƒ³ã‚°ï¼ˆLatent Semantic Indexing, LSIï¼‰ã¨ã„ã†ã®ã¯æƒ…å ±æ¤œç´¢ã®åˆ†é‡ã§ã®å‘¼ã³æ–¹ã§ã€è‡ªç„¶è¨€èªå‡¦ç†ã®æ–‡è„ˆã ã¨æ½œåœ¨æ„å‘³è§£æï¼ˆLatent Semantic Analysis, LSAï¼‰ã¨ã„ã†ã‚‰ã—ã„ã€‚

```{r}
#| label: create-dfm-2
dfm <-
  dplyr::tbl(con, "tokens") |>
  dplyr::filter(
    pos %in% c(
      "åè©", "åè©B", "åè©C",
      "åœ°å", "äººå", "çµ„ç¹”å", "å›ºæœ‰åè©",
      "å‹•è©", "æœªçŸ¥èª", "ã‚¿ã‚°"
    )
  ) |>
  dplyr::mutate(
    token = dplyr::if_else(is.na(original), token, original),
    token = paste(token, pos, sep = "/")
  ) |>
  dplyr::count(doc_id, token) |>
  dplyr::collect() |>
  tidytext::cast_dfm(doc_id, token, n) |>
  quanteda::dfm_trim(min_termfreq = 10) |>
  quanteda::dfm_tfidf(scheme_tf = "prop") |>
  rlang::as_function(
    ~ quanteda::dfm_subset(., quanteda::rowSums(.) > 0)
  )()

dfm
```

ã“ã“ã§ã¯300åˆ—ãã‚‰ã„ã—ã‹ãªã„ã®ã§å¤§ã—ãŸã“ã¨ãªã„ãŒã€ç‰¹å¾´é‡ã®æ•°ãŒå¤šã„æ–‡æ›¸å˜èªè¡Œåˆ—ã‚’`as.matrix()`ã™ã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªä¸Šã§ã®ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãªã£ã¦ã—ã¾ã„ã€æ‰±ã„ã¥ã‚‰ã„ã€‚ãã“ã§ã€ã‚‚ã¨ã®æ–‡æ›¸å˜èªè¡Œåˆ—ã®ã‚‚ã¤æƒ…å ±ã‚’ã§ãã‚‹ã ã‘ä¿æŒã—ã¤ã¤ã€è¡Œåˆ—ã®æ¬¡å…ƒã‚’å‰Šæ¸›ã—ãŸã„ã¨ã„ã†ã¨ãã«ã€LSIã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚

ã¨ãã«ã€æ–‡æ›¸ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’ãŠã“ãªã†å ´åˆã§ã¯ã€ã©ã®èªå½™ãŒã©ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å±ã™ã‚‹è¦å› ã«ãªã£ã¦ã„ã‚‹ã‹ã¿ãŸã„ãªã“ã¨ã¯ã©ã†ã›ç¢ºèªã§ããªã„ã®ã§ã€ç‰¹å¾´é‡ã¯é©å½“ã«å‰Šæ¸›ã—ã¦ã—ã¾ã£ã¦å•é¡Œãªã„ã¨æ€ã†ã€‚

```{r}
#| label: check-obj-size
lobstr::obj_size(dfm)
lobstr::obj_size(as.matrix(dfm))
```

`quanteda:textmodels::textmodel_lsa(margin = "documents")`ã¨ã™ã‚‹ã¨ã€ç‰¹ç•°å€¤åˆ†è§£ï¼ˆTruncated SVDï¼‰ã® $D \simeq D_{k} = U_{k}\Sigma{}_{k}V^{T}_{k}$ ã¨ã„ã†å¼ã«ãŠã‘ã‚‹ $V_{k}$ ãŒæˆ»ã‚Šå€¤ã«ãã®ã¾ã¾æ®‹ã‚‹ï¼ˆ`margin="features"`ã ã¨ $U_{k}$ ãŒãã®ã¾ã¾æ®‹ã‚Šã€`"both"`ã§ä¸¡æ–¹ã¨ã‚‚ãã®ã¾ã¾æ®‹ã‚‹ï¼‰ã€‚

ç‰¹ç•°å€¤åˆ†è§£ã™ã‚‹è¡Œåˆ— $D$ ã«ã¤ã„ã¦ã€ã„ã¾ã€è¡Œå´ã«æ–‡æ›¸ãƒ»åˆ—å´ã«å˜èªãŒã‚ã‚‹æŒã¡æ–¹ã‚’ã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã¯ã€è¡Œåˆ— $D$ ã‚’ãƒ©ãƒ³ã‚¯ $k$ ã®è¡Œåˆ— $D_{k}$ ã§è¿‘ä¼¼ã—ãŸã„ï¼ˆãƒ©ãƒ³ã‚¯å‰Šæ¸›ã—ãŸã„ï¼‰ã¨ã„ã†ã‚ˆã‚Šã€ç‰¹å¾´é‡ã‚’æ¸›ã‚‰ã—ãŸã„ï¼ˆ $k$ åˆ—ã®è¡Œåˆ—ã«ã—ã¦ã—ã¾ã„ãŸã„ï¼‰ã¨æ€ã£ã¦ã„ã‚‹ãŸã‚ã€`dfm`ã« $V_{k}$ ã‚’ã‹ã‘ã‚‹ã€‚

```{r}
#| label: lsi
mat <- quanteda.textmodels::textmodel_lsa(dfm, nd = 50, margin = "documents")
mat <- dfm %*% mat$features

str(mat)
```

### éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

LSIã§æ¬¡å…ƒã‚’å‰Šæ¸›ã—ãŸè¡Œåˆ—ã«ã¤ã„ã¦ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’ãŠã“ãªã†ã€‚ã“ã“ã§ã¯ã€æ–‡æ›¸é–“ã®è·é›¢ã¨ã—ã¦ã‚³ã‚µã‚¤ãƒ³è·é›¢ã‚’ä½¿ã†ã“ã¨ã«ã™ã‚‹ã€‚

æ–‡æ›¸é–“ã®è·é›¢ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚

```{r}
#| label: plot-simil
#| fig-height: 8
g1 <- mat |>
  proxyC::simil(margin = 1, method = "ejaccard") |>
  rlang::as_function(~ 1 - .[1:100, 1:100])() |>
  as.dist() |>
  factoextra::fviz_dist() +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  labs(title = "ejaccard")

g2 <- mat |>
  proxyC::simil(margin = 1, method = "edice") |>
  rlang::as_function(~ 1 - .[1:100, 1:100])() |>
  as.dist() |>
  factoextra::fviz_dist() +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  labs(title = "edice")

g3 <- mat |>
  proxyC::simil(margin = 1, method = "cosine") |>
  rlang::as_function(~ 1 - .[1:100, 1:100])() |>
  as.dist() |>
  factoextra::fviz_dist() +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  labs(title = "cosine")

patchwork::wrap_plots(g1, g2, g3, nrow = 3)
```

éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¯ééšå±¤çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«æ¯”ã¹ã‚‹ã¨è¨ˆç®—é‡ãŒå¤šã„ãŸã‚ã€å€‹ä½“æ•°ãŒå¢—ãˆã‚‹ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã®ã«ã‚„ã‚„æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚

```{r}
#| label: hier-clust
dat <- mat |>
  proxyC::simil(margin = 1, method = "cosine") |>
  rlang::as_function(~ 1 - .)()

clusters <-
  as.dist(dat) |>
  hclust(method = "ward.D2")

cluster::silhouette(cutree(clusters, k = 5), dist = dat) |>
  factoextra::fviz_silhouette(print.summary = FALSE) +
  theme_classic() +
  theme(axis.text.x = element_blank())
```

### ééšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ğŸ³

å¿…ãšã—ã‚‚ã‚¯ãƒ©ã‚¹ã‚¿ã®éšå±¤æ§‹é€ ã‚’ç¢ºèªã—ãŸã„ã‚ã‘ã§ã¯ãªã„å ´åˆã€`kmeans()`ã ã¨è¨ˆç®—ãŒæ—©ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚

ãŸã ã€ã€ŒK-meansã¯ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã‹ã‚‰ã®ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã§ã‚¯ãƒ©ã‚¹ã‚¿ã‚’åˆ†ã‘ã‚‹ã€ï¼ˆ[æ©Ÿæ¢°å­¦ç¿’å¸³](https://chokkan.github.io/mlnote/unsupervised/01kmeans.html#id18)ï¼‰ãŸã‚ã€ç‰¹å¾´é‡ã®æ•°ãŒå¢—ãˆã¦ãã‚‹ã¨ã‚¯ãƒ©ã‚¹ã‚¿ã®æ¯”ç‡ãŒãŠã‹ã—ããªã‚ŠãŒã¡ã€‚

```{r}
#| label: kmeans
clusters <- kmeans(mat, centers = 5, iter.max = 100, algorithm = "Lloyd")

cluster::silhouette(clusters$cluster, dist = dat) |>
  factoextra::fviz_silhouette(print.summary = FALSE) +
  theme_classic() +
  theme(axis.text.x = element_blank())
```

spherical k-meansã®å®Ÿè£…ã§ã‚ã‚‹[skmeans](https://cran.r-project.org/package=skmeans)ã ã¨ã‚¯ãƒ©ã‚¹ã‚¿ã®æ¯”ç‡ã¯ã„ãã‚‰ã‹ãƒã‚·ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚

```{r}
#| label: skmeans
clusters <-
  skmeans::skmeans(
    as.matrix(mat),
    k = 5,
    method = "pclust",
    control = list(maxiter = 100)
  )

cluster::silhouette(clusters$cluster, dist = dat) |>
  factoextra::fviz_silhouette(print.summary = FALSE) +
  theme_classic() +
  theme(axis.text.x = element_blank())
```

## ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ï¼ˆA.6.3-4ï¼‰

### ãƒˆãƒ”ãƒƒã‚¯æ•°ã®æ¢ç´¢

LDAã®ãƒˆãƒ”ãƒƒã‚¯æ•°ã®æ¢ç´¢ã¯ã€å®Ÿéš›ã«fitã—ã¦ã¿ã¦æŒ‡æ¨™ã®ã‚ˆã‹ã£ãŸãƒˆãƒ”ãƒƒã‚¯æ•°ã‚’æ¡ç”¨ã™ã‚‹ã¿ãŸã„ãªã‚„ã‚Šæ–¹ã‚’ã™ã‚‹ã€‚

```{r}
#| label: create-dfm-3
dfm <-
  dplyr::tbl(con, "tokens") |>
  dplyr::filter(
    pos %in% c(
      "åè©", "åè©B", "åè©C",
      "åœ°å", "äººå", "çµ„ç¹”å", "å›ºæœ‰åè©",
      "å‹•è©", "æœªçŸ¥èª", "ã‚¿ã‚°"
    )
  ) |>
  dplyr::mutate(
    token = dplyr::if_else(is.na(original), token, original),
    token = paste(token, pos, sep = "/")
  ) |>
  dplyr::count(doc_id, token) |>
  dplyr::collect() |>
  tidytext::cast_dfm(doc_id, token, n)
```

ã“ã“ã§ã¯ã€ãƒˆãƒ”ãƒƒã‚¯æ•°ã‚’5ã‹ã‚‰15ã¾ã§å¤‰åŒ–ã•ã›ã‚‹ã€‚`seededlda::textmodel_lda(auto_iter=TRUE)`ã¨ã™ã‚‹ã¨ã€ã‚¹ãƒ†ãƒƒãƒ—ãŒ`max_iter`ä»¥ä¸‹ã§ã‚ã£ã¦ã‚‚æ¡ä»¶ã«ã‚ˆã£ã¦ã‚®ãƒ–ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ‰“ã¡åˆ‡ã‚‹æŒ™å‹•ã«ãªã‚‹ã€‚

```{r}
#| label: divergence
#| cache: true
divergence <-
  purrr::map(5:15, \(.x) {
    lda_fit <-
      seededlda::textmodel_lda(dfm, k = .x, batch_size = 0.2, auto_iter = TRUE, verbose = FALSE)
    tibble::tibble(
      topics = .x,
      Deveaud2014 = seededlda::divergence(lda_fit, regularize = FALSE),
      WatanabeBaturo2023 = seededlda::divergence(lda_fit, min_size = .04, regularize = TRUE)
    )
  }) |>
  purrr::list_rbind()
```

Deveaud2014ã¨ã„ã†åˆ—ã¯ã€[ldatuning](https://cran.r-project.org/package=ldatuning)ã§ç¢ºèªã§ãã‚‹åŒåã®å€¤ã¨åŒã˜æŒ‡æ¨™ã€‚WatanabeBaturo2023ã¨ã„ã†åˆ—ã¯ã€Deveaud2014ã«ã¤ã„ã¦ãƒˆãƒ”ãƒƒã‚¯ã®æ¯”ç‡ãŒé–¾å€¤ã‚’ä¸‹å›ã‚‹ã¨ãã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’åŠ ãˆã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ãŸæŒ‡æ¨™ã€‚ã©ã¡ã‚‰ã‚‚å¤§ãã„ã»ã†ãŒã‚ˆã„æŒ‡æ¨™ãªã®ã§ã€åŸºæœ¬çš„ã«ã¯å€¤ãŒå¤§ãããªã£ã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯æ•°ã‚’é¸ã¶ã€‚

```{r}
#| label: plot-divergence
ggplot(divergence, aes(topics)) +
  geom_line(aes(y = Deveaud2014, color = "Deveaud2014")) +
  geom_line(aes(y = WatanabeBaturo2023, color = "WatanabeBaturo2023")) +
  scale_x_continuous(breaks = 5:15) +
  theme_bw() +
  ylab("Divergence")
```

### Distributed LDA

```{r}
#| label: fit-lda
#| cache: true
lda_fit <-
  seededlda::textmodel_lda(dfm, k = 9, batch_size = 0.2, verbose = FALSE)

seededlda::sizes(lda_fit)
```

### ãƒˆãƒ”ãƒƒã‚¯ã¨ãã®å‡ºç¾ä½ç½®

```{r}
#| label: topic-position
dat <- tbl |>
  dplyr::transmute(
    doc_id = doc_id,
    topic = seededlda::topics(lda_fit)[as.character(doc_id)],
  ) |>
  dplyr::filter(!is.na(topic)) # dfmã‚’ã¤ãã£ãŸæ™‚ç‚¹ã§å˜èªã‚’å«ã¾ãªã„æ–‡æ›¸ã¯ãƒˆãƒ”ãƒƒã‚¯ã®å‰²ã‚Šå½“ã¦ãŒãªã„ãŸã‚ã€å–ã‚Šé™¤ã

dat |>
  ggplot(aes(x = doc_id)) +
  geom_raster(aes(y = topic, fill = topic), show.legend = FALSE) +
  theme_classic() +
  theme(axis.text.x = element_blank())
```

### å˜èªã®ç”Ÿèµ·ç¢ºç‡

```{r}
#| label: phi
dat <-
  t(lda_fit$phi) |>
  dplyr::as_tibble(
    .name_repair = ~ paste0("topic", 1:9),
    rownames = "word"
  ) |>
  tidyr::pivot_longer(starts_with("topic"), names_to = "topic", values_to = "phi") |>
  dplyr::mutate(phi = signif(phi, 3)) |>
  dplyr::slice_max(phi, n = 20, by = topic)

reactable::reactable(
  dat,
  filterable = TRUE,
  defaultColDef = reactable::colDef(
    cell = reactablefmtr::data_bars(dat, text_position = "outside-base")
  )
)
```

## ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºï¼ˆA.6.6-8ï¼‰

`quanteda.textmodels::textmodel_nb()`ã§åˆ†é¡ã™ã‚‹ä¾‹ã€‚ã“ã“ã§ã¯ã€LexRankã®ç¯€ã§æŠ½å‡ºã—ãŸ`scores`ã®ä»˜ã„ã¦ã„ã‚‹æ–‡æ›¸ã‚’ä½¿ã£ã¦å­¦ç¿’ã™ã‚‹ã€‚äº¤å·®æ¤œè¨¼ã¯ã—ãªã„ã€‚

```{r}
#| label: naive-bayes
dfm <-
  dplyr::tbl(con, "tokens") |>
  dplyr::filter(
    pos %in% c(
      "åè©", # "åè©B", "åè©C",
      "åœ°å", "äººå", "çµ„ç¹”å", "å›ºæœ‰åè©",
      "å‹•è©", "æœªçŸ¥èª", "ã‚¿ã‚°"
    )
  ) |>
  dplyr::mutate(
    token = dplyr::if_else(is.na(original), token, original),
    token = paste(token, pos, sep = "/")
  ) |>
  dplyr::count(doc_id, token) |>
  dplyr::collect() |>
  tidytext::cast_dfm(doc_id, token, n) |>
  quanteda::dfm_tfidf(scheme_tf = "prop")

labels <- tbl |>
  dplyr::mutate(section = factor(section, labels = c("ä¸Š", "ä¸­", "ä¸‹"))) |>
  dplyr::filter(doc_id %in% quanteda::docnames(dfm)) |>
  dplyr::pull(section, doc_id)

nb_fit <- dfm |>
  quanteda::dfm_subset(
    quanteda::docnames(dfm) %in% names(scores)
  ) |>
  rlang::as_function(~ {
    # dfmã«æ ¼ç´ã™ã‚‹ã¨æ–‡æ›¸ã®é †ç•ªãŒå…¥ã‚Œæ›¿ã‚ã‚‹ã®ã§ã€labelsã®é †ç•ªã‚’ã‚ã‚ã›ãªã‘ã‚Œã°ãªã‚‰ãªã„
    quanteda.textmodels::textmodel_nb(., labels[quanteda::docnames(.)])
  })()

dat <- tbl |>
  dplyr::mutate(section = factor(section, labels = c("ä¸Š", "ä¸­", "ä¸‹"))) |>
  dplyr::filter(doc_id %in% quanteda::docnames(dfm)) |>
  dplyr::mutate(.pred = predict(nb_fit, dfm)[as.character(doc_id)]) # äºˆæ¸¬å€¤ã®é †ç•ªã‚’ã‚ã‚ã›ã‚‹å¿…è¦ãŒã‚ã‚‹

yardstick::conf_mat(dat, section, .pred) # æ··åŒè¡Œåˆ—

yardstick::accuracy(dat, section, .pred) # æ­£è§£ç‡

yardstick::f_meas(dat, section, .pred) # Få€¤
```

ç²¾åº¦ã‚ˆãåˆ†é¡ã™ã‚‹ã“ã¨ã‚ˆã‚Šã‚‚ã€å„ã‚«ãƒ†ã‚´ãƒªã«ãŠã‘ã‚‹ã€Œã‚¹ã‚³ã‚¢ã€ï¼ˆå°¤åº¦ï¼‰ã®æ¯”ã‚’è¦‹ã‚‹ã®ãŒç›®çš„ã§ãƒŠã‚¤ãƒ¼ãƒ–ãƒ™ã‚¤ã‚ºã‚’ä½¿ã£ã¦ã„ã‚‹ã¯ãšãªã®ã§ã€ç¢ºèªã™ã‚‹ã€‚

```{r}
#| label: coef
dat <-
  coef(nb_fit) |>
  dplyr::as_tibble(rownames = "token") |>
  rlang::as_function(~ {
    s <- t(coef(nb_fit)) |> colSums()
    dplyr::mutate(.,
      across(where(is.numeric), ~ . / s),
      var = t(coef(nb_fit)) |> cov() |> diag(),
      across(where(is.numeric), ~ signif(., 3))
    )
  })() |>
  dplyr::slice_max(var, n = 50)

reactable::reactable(
  dat,
  filterable = TRUE,
  defaultColDef = reactable::colDef(
    cell = reactablefmtr::data_bars(dat, text_position = "outside-base")
  )
)
```

---

```{r}
#| label: cleanup
duckdb::dbDisconnect(con)
duckdb::duckdb_shutdown(drv)

sessioninfo::session_info(info = "packages")
```
